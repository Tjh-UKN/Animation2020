# 基于神经网络的人物动作捕捉和角色动作生成文献综述
## 1 背景




## 2 里程碑

### 2.1 相位函数神经网络(PFNN)

### 2.2 模式自适应神经网络(MANN)

### 2.3 神经状态机(NSM)

基于场景理解的精确控制能够很好地帮助人物角色实现自我定位和导航，从而到达设定的目标位置。Holden等人提出了神经状态机(NSM)，一种引导角色通过精确场景交互实现目标驱动行为的框架。Holden等人在2017年提出的相位函数神经网络(PFNN)通过监督学习进行建模，生成高质量的人物动作并控制角色在有限区域内的运动。神经状态机将高质量的动作生成应用于支持人物角色与环境的交互，基于高阶的场景理解控制角色实现一系列复杂的人物动作。

神经状态机的贡献主要体现在以下几点：
1. 神经状态机构造出一种信号，将动作的相位编码成为高级动作描述标签和目标位置，通过数据集的深度学习，神经网络能够根据高级的指令生成高质量的人物角色动作。神经状态机以一种端到端的方式从数据集中分解权重，改良了传统的使用固定相位函数方法所带来的局限性，即只能应用于周期性的人物动作。
2. 神经状态机实现了一种双向控制框架，该框架综合了第一人称视角和目标视角对人物角色动作的预测，预测结果被实时地反馈给神经网络，从而产生连续的、高精确度的角色运动轨迹。
3. 神经状态机将体积表示方法应用于环境理解，改良了传统等高线表示方法所带来的局限性。该方法增强了了角色与凹形物体的交互效果，
4. 作者设计了一种增强数据集的方案，通过在数据集的每一帧中随机地切换环境变量中的几何物体，且不改变动作和交互的连贯性，使得神经网络获得更大的学习量，而不需要增大数据集的数据量。



## 3 相关工作

### 3.1

### 3.2

### 3.3
#### 1. 实现角色与环境动态交互的技术

**1.1 基于运动学的动作序列合成**

**基于模板的方法**将经过剪辑的运动片段插入场景中，并依据场景进行适应性调节。这些方法易于实现，但无法为大规模动画生成连续的运动数据。

1. Kang Hoon Lee等人于2006年提出了使用积木块作为“动作补丁”，构建大面积的虚拟环境，引导角色寻找达到目标位置的方法。积木块被赋予动作数据，包含了角色所被允许进行交互的动作集合。动作补丁模型实现了在较为复杂的环境中生成角色的动作。
2. Shailen Agrawal等人于2016年提出了一种目标驱动的运动模型，该法将人物角色的几种不同类型的脚步作为模板，通过调用和优化角色的脚步计划，并以此为基础生成人物角色全身的运动。该法实现了人物角色与环境之间更密切的交互。

**基于内核的方法**解决了基于模板的方法留下的问题。

1. Tomohiko Mukai等人为了解决地质统计学的相关问题，提出了将插入的动作片段视为参数空间内的数据预测的方法。
2. Jack M. Wang等人于2008年提出了高斯过程的动力学模型(GPDMs)，并将其应用于通过高维运动捕捉数据学习人类角色的姿势和动作。该类模型包含与动力学相关的低维隐式空间，以及从隐式空间到显式空间的映射。

**1.2 通过搜索的运动合成**

1. Min Gyu Choi等人于2003年提出了环境中的概率路线图，并且使用动捕数据和概率路线图生成二足动物角色的动作。这套方案以概率路径规划和多层次位移映射为基础，包括路线图构建、路线图搜索和运动合成三个部分。
2. Wan-Yen Lo和Matthias Zwicker 于2003年将强化学习应用于引导人物角色穿过门，于2012年实现引导人物角色绕开障碍物到达目的地。
3. Safonova和Hodgins于2007年引入A*搜索算法，用于混合动作插值的权重从而产生一个新的运动。此模型相当于一个参数化的图结构。Jianyuan Min等人使用最大后验估计(MAP)优化了动作权重的混合过程。

**1.3 通过局部优化或随机优化合成运动**。Igor Mordatch等人以一种局部优化策略——接触不变的优化方法为内核，提出了一种动作合成框架。Wenping Zhao等人使用一种随机优化策略——微粒群优化算法生成人物抓取的动作。

#### 2. 应用于合成密切交互的深度学习技术

**2.1 深度监督学习技术**

1. Katerina Fragkiadaki等人在2015年将长短期记忆神经网络( Long Short Term Memory Networks, LSTMs)应用于角色移动的动画模拟；Zimo Li、Ruben Villegas等人的团队将该技术应用于更为复杂的人物动作的刻画。
2. Zimo Li等人于2017年通过自适应的递归神经网络(auto-conditioned Recurrent Neural Network, RNN)的Teacher Forcing训练机制，改善了LSTMs随着错误的积累模拟精确度逐渐下降的问题。
3. Shaojie Bai等人于2018年指出使用简单的卷积神经网络结构进行模拟的效果优于RNN和LSTMs。
4. Daniel Holden等人于2016年将时间卷积应用于这一领域的研究，并于2017年提出相位函数神经网络(PFNN)，用以进行人物角色运动的生成。
5. Robert A. Jacobs在1991年提出的多专家模型(the mixture of experts)是一种监督学习模型。以此为基础，He Zhang等人于2018年提出模式自适应神经网络(mode-adaptive neural network, MANN)，用以模拟四足动物的运动。该模型由预测神经网络和一个门网络组成。

**2.2 深度强化学习技术**

1. 深度强化学习被广泛应用于人物动作的模拟。Xue Bin Peng等人于2018年前后引入参考数据(reference data)和视频数据进行训练，弥补了由单一的数据反馈带来的不足。
2. Wenhao Yu等人于2018年提出了一种训练对称和节能的运动模式的方法。通过为损失函数引入不对称的惩罚项，以及使用额外的辅助学习(locomotion curriculum learning)，生成了更符合人类认知的行走动作。


## 4 应用和展望

